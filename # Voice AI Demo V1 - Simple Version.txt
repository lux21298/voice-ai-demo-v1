# Voice AI Demo V1 - Simple Version
## ğŸ¯ Má»¥c tiÃªu: Build Ä‘Æ°á»£c trong 3 ngÃ y

## Overview
- **Äá»™ phá»©c táº¡p**: â­â­â˜†â˜†â˜† (2/5)
- **Thá»i gian**: 3 ngÃ y
- **Skill cáº§n**: Copy-paste code + Basic debugging
- **Cost**: <$5/thÃ¡ng cho testing

## Tech Stack (Tá»‘i giáº£n)
```
Next.js 14 (1 project)
    â†“
Vercel (free hosting)
    â†“
OpenAI API (STT + TTS + Chat)
    â†“
MCP Server (existing)
```

## Features Included âœ…
1. **Voice Input**: Click button Ä‘á»ƒ record (5-10 giÃ¢y max)
2. **Speech-to-Text**: DÃ¹ng Whisper API
3. **MCP Search**: Gá»i search_bootcamp_content
4. **AI Response**: GPT-4o-mini generate answer
5. **Text-to-Speech**: Convert response to audio
6. **Language**: Tiáº¿ng Viá»‡t + English (auto-detect)

## Features NOT Included âŒ
- Phone calls
- Real-time streaming
- Conversation history
- User authentication
- Booking functions
- Complex UI animations
- Error recovery
- Caching

## Project Structure (SiÃªu Ä‘Æ¡n giáº£n)
```
voice-demo-v1/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx          # Main UI (1 file)
â”‚   â”œâ”€â”€ layout.tsx        # Default layout
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ voice/
â”‚           â””â”€â”€ route.ts  # Single API endpoint
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ openai.ts        # OpenAI helper (20 lines)
â”‚   â””â”€â”€ mcp-client.ts    # MCP connection (30 lines)
â”œâ”€â”€ components/
â”‚   â””â”€â”€ VoiceRecorder.tsx # Record component (50 lines)
â”œâ”€â”€ .env.local           # API keys
â””â”€â”€ package.json
```

## Day-by-Day Plan

### ğŸ“… Day 1: Setup & Basic Recording
**Má»¥c tiÃªu**: Record voice vÃ  hiá»ƒn thá»‹ text

**Tasks**:
1. Create Next.js project
2. Install packages (openai, react-media-recorder)
3. Create recording UI vá»›i 1 button
4. Implement Whisper STT
5. Display transcription

**Test checkpoint**: NÃ³i "Hello" â†’ Hiá»ƒn thá»‹ "Hello" trÃªn screen

### ğŸ“… Day 2: Connect MCP & Generate Response
**Má»¥c tiÃªu**: Search MCP vÃ  generate answer

**Tasks**:
1. Create MCP client function
2. Add API route Ä‘á»ƒ proxy MCP calls
3. Integrate GPT-4o-mini
4. Generate response tá»« MCP results
5. Display text response

**Test checkpoint**: Há»i "há»c phÃ­ bao nhiÃªu" â†’ Nháº­n cÃ¢u tráº£ lá»i text

### ğŸ“… Day 3: Add TTS & Polish
**Má»¥c tiÃªu**: Complete voice loop & basic styling

**Tasks**:
1. Implement OpenAI TTS
2. Add audio player cho response
3. Support tiáº¿ng Viá»‡t
4. Basic Tailwind styling
5. Deploy to Vercel

**Test checkpoint**: Full flow voice â†’ text â†’ response â†’ audio

## Detailed Prompts cho Claude VSCode

### ğŸ”§ Initial Setup Prompt
```
Create a Next.js 14 app vá»›i TypeScript cho voice AI demo. Requirements:

1. Single page app vá»›i minimalist UI
2. Má»™t button lá»›n "ğŸ¤ Nháº¥n Ä‘á»ƒ nÃ³i" á»Ÿ giá»¯a
3. Display area cho transcript vÃ  response
4. Audio player cho TTS response

Tech stack:
- Next.js 14 vá»›i App Router
- TypeScript
- Tailwind CSS cho styling
- react-media-recorder cho voice recording

Táº¡o structure:
- /app/page.tsx - main UI
- /components/VoiceRecorder.tsx - recording logic
- /app/api/voice/route.ts - API endpoint

Keep it SUPER simple. No fancy animations. Focus on functionality.
```

### ğŸ¤ Voice Recording Prompt
```
Implement voice recording trong VoiceRecorder component:

Requirements:
1. DÃ¹ng react-media-recorder library
2. Record maximum 10 giÃ¢y
3. Format: audio/webm hoáº·c audio/wav
4. Show recording status (recording/processing/idle)
5. Auto-stop sau 10 giÃ¢y

UI states:
- Idle: "ğŸ¤ Nháº¥n Ä‘á»ƒ nÃ³i"
- Recording: "ğŸ”´ Äang ghi... (X giÃ¢y)"
- Processing: "â³ Äang xá»­ lÃ½..."

Error handling:
- No microphone permission
- Recording failed
- Show simple error message

Output: Blob audio Ä‘á»ƒ send to API
```

### ğŸ”Š OpenAI Integration Prompt
```
Create /lib/openai.ts vá»›i 3 functions:

1. transcribeAudio(audioBlob): 
   - DÃ¹ng Whisper API
   - Return transcript text
   - Auto-detect language

2. generateResponse(transcript, mcpResults):
   - DÃ¹ng GPT-4o-mini
   - System prompt: "Answer in same language as question. Context: {mcpResults}"
   - Max 100 tokens response

3. textToSpeech(text, language):
   - DÃ¹ng TTS API
   - Voice: "alloy" for English, "nova" for Vietnamese
   - Return audio URL

Use environment variables:
- OPENAI_API_KEY

Add error handling vá»›i try-catch, return error messages.
```

### ğŸ”Œ MCP Client Prompt
```
Create /lib/mcp-client.ts Ä‘á»ƒ connect vá»›i MCP server:

MCP server URL: http://localhost:3000/api/mcp

Implement searchBootcamp(query) function:
1. POST request vá»›i body:
   {
     "method": "search_bootcamp_content",
     "params": { "query": query }
   }

2. Handle response vÃ  extract results
3. Return simplified format:
   {
     success: boolean,
     data: any[],
     error?: string
   }

Add CORS handling qua Next.js API route /api/mcp/route.ts
Simple proxy Ä‘á»ƒ avoid CORS issues.
```

### ğŸ¨ UI Polish Prompt
```
Update main page.tsx vá»›i simple but clean UI:

Layout:
- Container max-w-2xl mx-auto
- Padding p-8
- Center everything

Components:
1. Header: "ğŸ“ Bootcamp Voice Assistant"
2. VoiceRecorder component (centered)
3. Transcript display (if exists):
   - Label: "Báº¡n nÃ³i:"
   - Gray background, rounded corners
4. Response display (if exists):
   - Label: "Tráº£ lá»i:"
   - Blue background, rounded corners
5. Audio player (if audio exists)

Colors:
- Background: white
- Primary: blue-600
- Text: gray-800
- Borders: gray-200

Mobile responsive vá»›i Tailwind classes.
```

### ğŸš€ API Endpoint Prompt
```
Create /app/api/voice/route.ts - single endpoint xá»­ lÃ½ all:

POST endpoint nháº­n FormData vá»›i audio file.

Flow:
1. Extract audio tá»« FormData
2. Call OpenAI Whisper â†’ get transcript
3. Call MCP search vá»›i transcript
4. Generate response vá»›i GPT-4o-mini + MCP results
5. Convert response to speech
6. Return JSON:
   {
     transcript: string,
     response: string,
     audioUrl: string,
     language: "vi" | "en"
   }

Error handling:
- Return 400 náº¿u no audio
- Return 500 vá»›i error message
- Log errors to console

Max processing time: 10 seconds
```

### ğŸŒ Deployment Prompt
```
Prepare Ä‘á»ƒ deploy lÃªn Vercel:

1. Update next.config.js náº¿u cáº§n
2. Add environment variables guide:
   - OPENAI_API_KEY
   - MCP_SERVER_URL (default: http://localhost:3000/api/mcp)

3. Create .env.example file

4. Update README.md vá»›i:
   - Setup instructions
   - Required ENV vars
   - How to run locally
   - How to deploy to Vercel

5. Add vercel.json náº¿u cáº§n special config

Note: MCP server cáº§n accessible tá»« internet náº¿u deploy production.
For demo, cÃ³ thá»ƒ mock MCP responses.
```

## Common Issues & Solutions

### Issue 1: Microphone Permission
```
Solution: Add clear message "Please allow microphone access"
Fallback: Text input field
```

### Issue 2: MCP Connection Failed
```
Solution: Add mock data for demo
const mockResponse = {
  "há»c phÃ­": "Há»c phÃ­ bootcamp lÃ  45 triá»‡u...",
  "thá»i gian": "KhÃ³a há»c kÃ©o dÃ i 16 tuáº§n..."
}
```

### Issue 3: OpenAI Rate Limit
```
Solution: 
- Add 1 second delay between requests
- Show "Please wait..." message
- Cache common questions locally
```

## Testing Checklist

### Basic Tests:
- [ ] Record 5 seconds audio â†’ transcribe correctly
- [ ] Ask in Vietnamese â†’ response in Vietnamese  
- [ ] Ask in English â†’ response in English
- [ ] Ask about tuition â†’ get MCP results
- [ ] Play audio response successfully

### Error Tests:
- [ ] No microphone â†’ show error
- [ ] MCP offline â†’ use fallback
- [ ] Long recording â†’ auto stop at 10s
- [ ] No API key â†’ clear error message

## Success Criteria V1

âœ… **Minimum Viable**:
- User can record voice
- See transcription
- Get text response
- Hear audio response

âœ… **Good Enough**:
- Works in Vietnamese & English
- Connects to MCP successfully
- Deployed to Vercel
- Mobile responsive

âœ… **Nice to Have**:
- Loading animations
- Error messages in both languages
- Volume control for audio
- Copy response button

## Estimated Effort

### For Non-Developer vá»›i Claude:
- **Day 1**: 4-6 hours (lots of setup)
- **Day 2**: 3-4 hours (integration)
- **Day 3**: 2-3 hours (polish)
- **Total**: ~12 hours actual coding

### Complexity Points:
- Setup: â­â­ (follow instructions)
- Recording: â­â­ (use library)
- API calls: â­â­â­ (some debugging)
- MCP proxy: â­â­â­ (CORS issues)
- Deployment: â­ (Vercel is easy)

## Final Tips

1. **Start Simple**: Get voice â†’ text working first
2. **Use Mocks**: Mock MCP if connection issues
3. **Test Locally**: Don't deploy until working locally
4. **One Feature at a Time**: Don't try to do everything at once
5. **Ask Claude**: Break down errors into small questions

---

**Remember**: V1 is about WORKING, not PERFECT. Get basic flow working first!